services:
  #################
  # Backend API
  #################
  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile # Points to the updated Dockerfile
    container_name: ckguru_backend
    volumes:
      - ./backend/app:/app/app # Hot-reload for backend code
      # Mounts for alembic are still useful for development to see changes
      # without rebuilding the image every time.
      - ./backend/alembic.ini:/app/alembic.ini
      - ./backend/alembic:/app/alembic
      - ./shared:/app/shared # Shared directory hot-reload 
    ports:
      - "8000:8000"
    env_file:
      - .env
    environment:
      STORAGE_BASE_PATH: /app/persistent_data
    depends_on:
      db:
        condition: service_healthy # IMPORTANT: Wait for DB healthcheck
      broker:
        condition: service_started # Adjust condition as needed
      redis:
        condition: service_started
      minio:
        condition: service_healthy

  #################
  # Ingestion Worker
  #################
  ingestion-worker:
    build:
      context: . # Build context is root
      dockerfile: worker/ingestion/Dockerfile # Path to specific Dockerfile
    container_name: ckguru_ingestion_worker
    volumes:
      - ./worker/ingestion/app:/app/app # Worker-specific code hot-reload
      - ./shared:/app/shared           # Shared code hot-reload
      - app_data:/app/persistent_data # Volume for git clones
    env_file:
      - .env
    environment:
      STORAGE_BASE_PATH: /app/persistent_data # Needed for clone path logic
    depends_on:
      - broker
      - db
      - minio # Does ingestion *need* minio? Maybe not directly. Keep if utils access it.
      - redis # For results backend if enabled

  #################
  # Dataset Worker
  #################
  dataset-worker:
    build:
      context: .
      dockerfile: worker/dataset/Dockerfile
    container_name: ckguru_dataset_worker
    volumes:
      - ./worker/dataset/app:/app/app
      - ./shared:/app/shared
      # No app_data needed unless it reads clones directly (it shouldn't)
    env_file:
      - .env
    depends_on:
      - broker
      - db
      - minio
      - redis

  ######################### Commented out for future gpu bounded worker
  # #################
  # # Celery Worker
  # #################
  # worker:
  #   build:
  #     context: .
  #     dockerfile: worker/Dockerfile
  #   container_name: ckguru_worker
  #   volumes:
  #     - ./worker/app:/app/app # Optional: hot-reload 
  #     - ./shared:/app/shared # Shared directory hot-reload 
  #     - app_data:/app/persistent_data # For git clones
  #   env_file:
  #     - .env
  #   environment:
  #     STORAGE_BASE_PATH: /app/persistent_data
  #     # Ensure CUDA devices are visible (often handled by deploy key, but can be explicit)
  #     # NVIDIA_VISIBLE_DEVICES: all # Set this if needed
  #     NVIDIA_DRIVER_CAPABILITIES: compute,utility # Often needed
  #   depends_on:
  #     - broker
  #     - db
  #     - redis
  #     - minio
  #   # <<< --- GPU Configuration --- >>>
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             # count: 1 # Request exactly one GPU
  #             count: all # Request all available GPUs
  #             capabilities: [gpu] # Request GPU capabilities

  #################
  # Object Storage (MinIO)
  #################
  minio:
    image: minio/minio:RELEASE.2025-04-03T14-56-28Z # If cpu architecture does not support x86_64-v2 use RELEASE.2025-04-03T14-56-28Z-cpuv1 (cpuv1 variant)
    container_name: ckguru_minio
    env_file:
      - .env # Load MINIO_ROOT_USER, MINIO_ROOT_PASSWORD from .env
    environment:
      # These should match S3_ACCESS_KEY_ID and S3_SECRET_ACCESS_KEY in .env
      MINIO_ROOT_USER: ${S3_ACCESS_KEY_ID}
      MINIO_ROOT_PASSWORD: ${S3_SECRET_ACCESS_KEY}
    command: server /data --console-address ":9001" # Start server, data dir, console port
    ports:
      - "9000:9000" # API port
      - "9001:9001" # Console port
    volumes:
      - minio_data:/data # Persistent storage for MinIO buckets/objects
    healthcheck:
      test: ["CMD", "mc", "ready", "local"] # Use MinIO Client for healthcheck
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
  mc: # MinIO Client Helper Container (for creating bucket)
      image: minio/mc
      depends_on:
          minio:
              condition: service_healthy
      env_file:
          - .env # Need access keys
      entrypoint: >
          /bin/sh -c "
          echo 'Waiting for MinIO...' &&
          sleep 5 &&
          mc config host add local ${S3_ENDPOINT_URL:-http://minio:9000} ${S3_ACCESS_KEY_ID} ${S3_SECRET_ACCESS_KEY} --api S3v4 &&
          echo 'Checking if bucket ${S3_BUCKET_NAME} exists...' &&
          mc ls local/${S3_BUCKET_NAME} > /dev/null 2>&1 || (
              echo 'Bucket ${S3_BUCKET_NAME} does not exist. Creating...' &&
              mc mb local/${S3_BUCKET_NAME} &&
              echo 'Bucket ${S3_BUCKET_NAME} created.'
          ) || echo 'Bucket ${S3_BUCKET_NAME} already exists.'
          echo 'MinIO setup complete.'
          "

  #################
  # Frontend UI
  #################
  frontend:
    build:
      context: ./frontend # Context is the frontend directory
      dockerfile: Dockerfile
    container_name: ckguru_frontend
    ports:
      - "3000:80" # Map host port 3000 to Nginx container port 80
    depends_on:
      - backend # Usually depends on backend being available

  #################
  # Database
  #################
  db:
    image: postgres:15-alpine
    container_name: ckguru_db
    volumes:
      - postgres_data:/var/lib/postgresql/data # Persistent DB data
    env_file:
      - .env # For POSTGRES_USER, POSTGRES_PASSWORD, POSTGRES_DB
    ports:
      - "5432:5432" # Optional: Expose DB port to host for debugging
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 5s
      timeout: 10s
      retries: 5

  #################
  # Message Broker
  #################
  broker:
    image: rabbitmq:3.12-management-alpine
    container_name: ckguru_broker
    env_file:
      - .env # For RABBITMQ_DEFAULT_USER, RABBITMQ_DEFAULT_PASS
    ports:
      - "5672:5672"   # AMQP protocol port
      - "15672:15672" # Management UI port
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq # Persistent storage for RabbitMQ data

  #################
  # Result Backend (Redis)
  #################
  redis:
    image: redis:7-alpine
    container_name: ckguru_redis
    # ports: # Optional: Expose port 6379 to host for debugging if needed
    #   - "6379:6379"
    volumes:
      - redis_data:/data # Persistent storage for Redis data
    # Add a basic healthcheck (optional but good practice)
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

#################
# Volumes
#################
volumes:
  postgres_data: # Stores PostgreSQL data
  app_data:      # Stores git clones for worker
  redis_data:    # Stores Redis data (optional, but good for persistence)
  minio_data:    # Stores MinIO data (buckets/objects) for datasets, models, etc.
  rabbitmq_data: # Stores RabbitMQ message data, user configs, etc.