"""Add xai_results table

Revision ID: 286d37996c4b
Revises: ec155e27892c
Create Date: 2025-04-27 22:52:37.205377

"""

from typing import Sequence, Union

import sqlalchemy as sa
from alembic import op
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = "286d37996c4b"
down_revision: Union[str, None] = "ec155e27892c"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "xai_results",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("inference_job_id", sa.Integer(), nullable=False),
        sa.Column(
            "xai_type",
            sa.Enum(
                "SHAP",
                "LIME",
                "FEATURE_IMPORTANCE",
                "DECISION_PATH",
                "COUNTERFACTUALS",
                name="xai_type_enum",
            ),
            nullable=False,
        ),
        sa.Column(
            "status",
            sa.Enum("PENDING", "RUNNING", "SUCCESS", "FAILED", name="xai_status_enum"),
            nullable=False,
        ),
        sa.Column("result_data", sa.JSON(), nullable=True),
        sa.Column("status_message", sa.Text(), nullable=True),
        sa.Column("celery_task_id", sa.String(), nullable=True),
        sa.Column("started_at", sa.DateTime(timezone=True), nullable=True),
        sa.Column("completed_at", sa.DateTime(timezone=True), nullable=True),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
        ),
        sa.Column(
            "updated_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
        ),
        sa.ForeignKeyConstraint(
            ["inference_job_id"], ["inference_jobs.id"], ondelete="CASCADE"
        ),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint(
            "inference_job_id", "xai_type", name="uq_inference_job_xai_type"
        ),
    )
    op.create_index(
        op.f("ix_xai_results_celery_task_id"),
        "xai_results",
        ["celery_task_id"],
        unique=False,
    )
    op.create_index(op.f("ix_xai_results_id"), "xai_results", ["id"], unique=False)
    op.create_index(
        op.f("ix_xai_results_inference_job_id"),
        "xai_results",
        ["inference_job_id"],
        unique=False,
    )
    op.create_index(
        "ix_xai_results_job_id_type",
        "xai_results",
        ["inference_job_id", "xai_type"],
        unique=False,
    )
    op.create_index(
        op.f("ix_xai_results_status"), "xai_results", ["status"], unique=False
    )
    op.create_index(
        op.f("ix_xai_results_xai_type"), "xai_results", ["xai_type"], unique=False
    )
    op.alter_column(
        "inference_jobs",
        "input_reference",
        existing_type=postgresql.JSON(astext_type=sa.Text()),
        comment="Reference to input data (e.g., {'commit_hash': 'abc...', 'repo_id': 1, 'trigger_source': 'manual'})",
        existing_comment="Reference to input data (e.g., commit hash, feature dict, S3 path)",
        existing_nullable=False,
    )
    op.alter_column(
        "inference_jobs",
        "prediction_result",
        existing_type=postgresql.JSON(astext_type=sa.Text()),
        comment="Stored prediction output (e.g., {'prediction': 1, 'probability': 0.85})",
        existing_comment="Stored prediction output",
        existing_nullable=True,
    )
    op.drop_index("ix_inference_jobs_celery_task_id", table_name="inference_jobs")
    op.create_index(
        op.f("ix_inference_jobs_celery_task_id"),
        "inference_jobs",
        ["celery_task_id"],
        unique=False,
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f("ix_inference_jobs_celery_task_id"), table_name="inference_jobs")
    op.create_index(
        "ix_inference_jobs_celery_task_id",
        "inference_jobs",
        ["celery_task_id"],
        unique=True,
    )
    op.alter_column(
        "inference_jobs",
        "prediction_result",
        existing_type=postgresql.JSON(astext_type=sa.Text()),
        comment="Stored prediction output",
        existing_comment="Stored prediction output (e.g., {'prediction': 1, 'probability': 0.85})",
        existing_nullable=True,
    )
    op.alter_column(
        "inference_jobs",
        "input_reference",
        existing_type=postgresql.JSON(astext_type=sa.Text()),
        comment="Reference to input data (e.g., commit hash, feature dict, S3 path)",
        existing_comment="Reference to input data (e.g., {'commit_hash': 'abc...', 'repo_id': 1, 'trigger_source': 'manual'})",
        existing_nullable=False,
    )
    op.drop_index(op.f("ix_xai_results_xai_type"), table_name="xai_results")
    op.drop_index(op.f("ix_xai_results_status"), table_name="xai_results")
    op.drop_index("ix_xai_results_job_id_type", table_name="xai_results")
    op.drop_index(op.f("ix_xai_results_inference_job_id"), table_name="xai_results")
    op.drop_index(op.f("ix_xai_results_id"), table_name="xai_results")
    op.drop_index(op.f("ix_xai_results_celery_task_id"), table_name="xai_results")
    op.drop_table("xai_results")
    # ### end Alembic commands ###
