"""add ml models and jobs

Revision ID: ec155e27892c
Revises: ed8aa882ba7b
Create Date: 2025-04-07 18:21:28.236295

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = 'ec155e27892c'
down_revision: Union[str, None] = 'ed8aa882ba7b'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('hp_search_jobs',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('celery_task_id', sa.String(), nullable=True),
    sa.Column('status', sa.Enum('PENDING', 'RUNNING', 'SUCCESS', 'FAILED', 'REVOKED', name='job_status_enum'), nullable=False),
    sa.Column('status_message', sa.Text(), nullable=True),
    sa.Column('config', sa.JSON(), nullable=False, comment='Search configuration (model type, HP space, Optuna settings)'),
    sa.Column('dataset_id', sa.Integer(), nullable=False),
    sa.Column('optuna_study_name', sa.String(), nullable=False, comment='Unique name for the Optuna study'),
    sa.Column('best_trial_id', sa.Integer(), nullable=True, comment="Optuna's internal best trial ID"),
    sa.Column('best_params', sa.JSON(), nullable=True),
    sa.Column('best_value', sa.Float(), nullable=True),
    sa.Column('started_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('completed_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['dataset_id'], ['datasets.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_hp_search_jobs_celery_task_id'), 'hp_search_jobs', ['celery_task_id'], unique=True)
    op.create_index(op.f('ix_hp_search_jobs_dataset_id'), 'hp_search_jobs', ['dataset_id'], unique=False)
    op.create_index(op.f('ix_hp_search_jobs_id'), 'hp_search_jobs', ['id'], unique=False)
    op.create_index(op.f('ix_hp_search_jobs_optuna_study_name'), 'hp_search_jobs', ['optuna_study_name'], unique=True)
    op.create_index(op.f('ix_hp_search_jobs_status'), 'hp_search_jobs', ['status'], unique=False)
    op.create_table('training_jobs',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('celery_task_id', sa.String(), nullable=True),
    sa.Column('status', sa.Enum('PENDING', 'RUNNING', 'SUCCESS', 'FAILED', 'REVOKED', name='job_status_enum'), nullable=False),
    sa.Column('status_message', sa.Text(), nullable=True),
    sa.Column('config', sa.JSON(), nullable=False, comment='Training configuration used'),
    sa.Column('dataset_id', sa.Integer(), nullable=False),
    sa.Column('started_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('completed_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['dataset_id'], ['datasets.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_training_jobs_celery_task_id'), 'training_jobs', ['celery_task_id'], unique=True)
    op.create_index(op.f('ix_training_jobs_dataset_id'), 'training_jobs', ['dataset_id'], unique=False)
    op.create_index(op.f('ix_training_jobs_id'), 'training_jobs', ['id'], unique=False)
    op.create_index(op.f('ix_training_jobs_status'), 'training_jobs', ['status'], unique=False)
    op.create_table('ml_models',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('name', sa.String(), nullable=False, comment='Logical name for the model (e.g., commit_defect_classifier)'),
    sa.Column('version', sa.Integer(), nullable=False, comment='Version number for this model name'),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('model_type', sa.String(), nullable=False, comment='Type of the model (e.g., sklearn_randomforest, pytorch_cnn)'),
    sa.Column('s3_artifact_path', sa.String(), nullable=True, comment='URI to the saved model artifact in S3/MinIO'),
    sa.Column('dataset_id', sa.Integer(), nullable=True, comment='Dataset used for training/evaluation (optional)'),
    sa.Column('training_job_id', sa.Integer(), nullable=True, comment='Training job that created this model (optional)'),
    sa.Column('hp_search_job_id', sa.Integer(), nullable=True, comment='HP search job that resulted in this model (optional)'),
    sa.Column('hyperparameters', sa.JSON(), nullable=True, comment='Hyperparameters used for this specific model instance'),
    sa.Column('performance_metrics', sa.JSON(), nullable=True, comment='Key performance metrics (e.g., accuracy, f1)'),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['dataset_id'], ['datasets.id'], ondelete='SET NULL'),
    sa.ForeignKeyConstraint(['hp_search_job_id'], ['hp_search_jobs.id'], ondelete='SET NULL'),
    sa.ForeignKeyConstraint(['training_job_id'], ['training_jobs.id'], ondelete='SET NULL'),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('name', 'version', name='uq_ml_model_name_version'),
    sa.UniqueConstraint('s3_artifact_path')
    )
    op.create_index(op.f('ix_ml_models_dataset_id'), 'ml_models', ['dataset_id'], unique=False)
    op.create_index(op.f('ix_ml_models_hp_search_job_id'), 'ml_models', ['hp_search_job_id'], unique=False)
    op.create_index(op.f('ix_ml_models_id'), 'ml_models', ['id'], unique=False)
    op.create_index(op.f('ix_ml_models_model_type'), 'ml_models', ['model_type'], unique=False)
    op.create_index(op.f('ix_ml_models_name'), 'ml_models', ['name'], unique=False)
    op.create_index(op.f('ix_ml_models_training_job_id'), 'ml_models', ['training_job_id'], unique=False)
    op.create_index(op.f('ix_ml_models_version'), 'ml_models', ['version'], unique=False)
    op.create_table('inference_jobs',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('celery_task_id', sa.String(), nullable=True),
    sa.Column('status', sa.Enum('PENDING', 'RUNNING', 'SUCCESS', 'FAILED', 'REVOKED', name='job_status_enum'), nullable=False),
    sa.Column('status_message', sa.Text(), nullable=True),
    sa.Column('ml_model_id', sa.Integer(), nullable=False, comment='Model used for inference'),
    sa.Column('input_reference', sa.JSON(), nullable=False, comment='Reference to input data (e.g., commit hash, feature dict, S3 path)'),
    sa.Column('prediction_result', sa.JSON(), nullable=True, comment='Stored prediction output'),
    sa.Column('started_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('completed_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['ml_model_id'], ['ml_models.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_inference_jobs_celery_task_id'), 'inference_jobs', ['celery_task_id'], unique=True)
    op.create_index(op.f('ix_inference_jobs_id'), 'inference_jobs', ['id'], unique=False)
    op.create_index(op.f('ix_inference_jobs_ml_model_id'), 'inference_jobs', ['ml_model_id'], unique=False)
    op.create_index(op.f('ix_inference_jobs_status'), 'inference_jobs', ['status'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_inference_jobs_status'), table_name='inference_jobs')
    op.drop_index(op.f('ix_inference_jobs_ml_model_id'), table_name='inference_jobs')
    op.drop_index(op.f('ix_inference_jobs_id'), table_name='inference_jobs')
    op.drop_index(op.f('ix_inference_jobs_celery_task_id'), table_name='inference_jobs')
    op.drop_table('inference_jobs')
    op.drop_index(op.f('ix_ml_models_version'), table_name='ml_models')
    op.drop_index(op.f('ix_ml_models_training_job_id'), table_name='ml_models')
    op.drop_index(op.f('ix_ml_models_name'), table_name='ml_models')
    op.drop_index(op.f('ix_ml_models_model_type'), table_name='ml_models')
    op.drop_index(op.f('ix_ml_models_id'), table_name='ml_models')
    op.drop_index(op.f('ix_ml_models_hp_search_job_id'), table_name='ml_models')
    op.drop_index(op.f('ix_ml_models_dataset_id'), table_name='ml_models')
    op.drop_table('ml_models')
    op.drop_index(op.f('ix_training_jobs_status'), table_name='training_jobs')
    op.drop_index(op.f('ix_training_jobs_id'), table_name='training_jobs')
    op.drop_index(op.f('ix_training_jobs_dataset_id'), table_name='training_jobs')
    op.drop_index(op.f('ix_training_jobs_celery_task_id'), table_name='training_jobs')
    op.drop_table('training_jobs')
    op.drop_index(op.f('ix_hp_search_jobs_status'), table_name='hp_search_jobs')
    op.drop_index(op.f('ix_hp_search_jobs_optuna_study_name'), table_name='hp_search_jobs')
    op.drop_index(op.f('ix_hp_search_jobs_id'), table_name='hp_search_jobs')
    op.drop_index(op.f('ix_hp_search_jobs_dataset_id'), table_name='hp_search_jobs')
    op.drop_index(op.f('ix_hp_search_jobs_celery_task_id'), table_name='hp_search_jobs')
    op.drop_table('hp_search_jobs')
    # ### end Alembic commands ###
