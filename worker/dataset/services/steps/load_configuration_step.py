# worker/dataset/services/steps/load_configuration_step.py
import logging

from services.context import DatasetContext

# Import interfaces and concrete repositories/services
from services.interfaces import IDatasetGeneratorStep, IRepositoryFactory

from shared.exceptions import NotFoundError  # For cleaner error handling
from shared.repositories import (
    BotPatternRepository,
    DatasetRepository,
    RepositoryRepository,
)

# Import models and schemas
from shared.schemas.dataset import DatasetConfig  # Schema for validation
from shared.schemas.enums import DatasetStatusEnum
from shared.services.interfaces import IJobStatusUpdater
from shared.utils.pipeline_logging import StepLogger

logger = logging.getLogger(__name__)


class LoadConfigurationStep(IDatasetGeneratorStep):
    """Loads dataset definition, repository info, bot patterns, config, and updates initial status."""

    name = "Load Configuration"

    def execute(
        self,
        context: DatasetContext,
        *,
        repo_factory: IRepositoryFactory,
        job_status_updater: IJobStatusUpdater,
        **kwargs,
    ) -> DatasetContext:
        log_prefix = f"Task {context.task_instance.request.id} - Step [{self.name}]"
        step_logger = StepLogger(logger, log_prefix=log_prefix)
        step_logger.info(
            f"Loading configuration for Dataset ID: {context.dataset_id}..."
        )

        dataset_repo: DatasetRepository = repo_factory.get_dataset_repo()
        repository_repo: RepositoryRepository = repo_factory.get_repository_repo()
        bot_pattern_repo: BotPatternRepository = repo_factory.get_bot_pattern_repo()

        try:
            # --- Load Dataset Definition ---
            context.dataset_db = dataset_repo.get_by_id(context.dataset_id)
            if not context.dataset_db:
                raise NotFoundError(
                    f"Dataset definition {context.dataset_id} not found."
                )

            # Check if already being generated by another task
            if (
                context.dataset_db.status == DatasetStatusEnum.GENERATING
                and context.dataset_db.celery_task_id
                != context.task_instance.request.id
            ):
                msg = f"Dataset {context.dataset_id} generation already in progress by task {context.dataset_db.celery_task_id}."
                step_logger.warning(msg)
                # Raise a specific exception type? Or just ValueError?
                raise ValueError(msg)  # Let pipeline runner handle this

            # --- Load Repository ---
            context.repository_db = repository_repo.get_by_id(
                context.dataset_db.repository_id
            )
            if not context.repository_db:
                raise NotFoundError(
                    f"Repository {context.dataset_db.repository_id} not found for dataset {context.dataset_id}."
                )

            # --- Load Bot Patterns ---
            # Use BotPatternRepository method
            context.bot_patterns_db = list(
                bot_pattern_repo.get_patterns(
                    repository_id=context.repository_db.id, include_global=True
                )
            )
            step_logger.info(
                f"Fetched {len(context.bot_patterns_db)} applicable bot patterns."
            )

            # --- Load and Validate Config ---
            config_dict = (
                context.dataset_db.config
                if isinstance(context.dataset_db.config, dict)
                else {}
            )
            try:
                context.dataset_config = DatasetConfig(
                    **config_dict
                )  # Validate against schema
                step_logger.info("Dataset configuration loaded and validated.")
            except Exception as config_err:  # Catch Pydantic ValidationError or others
                step_logger.error(
                    f"Invalid dataset configuration: {config_err}", exc_info=True
                )
                raise ValueError(
                    f"Invalid dataset configuration: {config_err}"
                ) from config_err

            if not context.dataset_config.feature_columns:
                raise ValueError(
                    "Dataset configuration must specify 'feature_columns'."
                )
            if not context.dataset_config.target_column:
                raise ValueError("Dataset configuration must specify 'target_column'.")

            # --- Update DB Status to GENERATING ---
            updated = job_status_updater.update_dataset_start(
                dataset_id=context.dataset_id, task_id=context.task_instance.request.id
            )
            if not updated:
                # If status update fails, we cannot proceed reliably
                raise RuntimeError(
                    "Failed to update dataset status to GENERATING in DB."
                )

            step_logger.info(
                "Configuration loaded successfully. Dataset status set to GENERATING."
            )

        except NotFoundError as e:
            step_logger.error(f"Configuration loading failed: {e}")
            job_status_updater.update_dataset_completion(
                context.dataset_id,
                DatasetStatusEnum.FAILED,
                f"Configuration error: {e}",
            )
            raise  # Re-raise critical error
        except ValueError as e:  # Catch config validation errors or GENERATING conflict
            step_logger.error(f"Configuration loading failed: {e}")
            # Try to update status if dataset was loaded
            if context.dataset_db:
                job_status_updater.update_dataset_completion(
                    context.dataset_id,
                    DatasetStatusEnum.FAILED,
                    f"Configuration error: {e}",
                )
            raise  # Re-raise critical error
        except Exception as e:
            step_logger.error(
                f"Unexpected error loading configuration: {e}", exc_info=True
            )
            # Try to update status if dataset was loaded
            if context.dataset_db:
                job_status_updater.update_dataset_completion(
                    context.dataset_id,
                    DatasetStatusEnum.FAILED,
                    f"Unexpected error during config load: {e}",
                )
            raise RuntimeError("Unexpected error during configuration load") from e

        return context
